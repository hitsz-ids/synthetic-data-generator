{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5w5Oktvr7bC"
   },
   "source": [
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<p align=\"center\">\n",
    "\n",
    "\n",
    "# üöÄ Synthetic Data Generator\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "The Synthetic Data Generator (SDG) is a specialized framework designed to generate high-quality structured tabular data.\n",
    "\n",
    "Synthetic data does not contain any sensitive information, yet it retains the essential characteristics of the original data, making it exempt from privacy regulations such as GDPR and ADPPA.\n",
    "\n",
    "High-quality synthetic data can be safely utilized across various domains including data sharing, model training and debugging, system development and testing, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OikMoGinr7bF",
    "outputId": "3ce73c4d-c7e5-4160-b912-0bc78d6d9a11",
    "ExecuteTime": {
     "end_time": "2024-11-29T03:16:48.397254Z",
     "start_time": "2024-11-29T03:16:27.783975Z"
    }
   },
   "source": [
    "# install from git\n",
    "!pip install git+https://github.com/hitsz-ids/synthetic-data-generator.git"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting git+https://github.com/hitsz-ids/synthetic-data-generator.git\n",
      "  Cloning https://github.com/hitsz-ids/synthetic-data-generator.git to c:\\users\\elvin\\appdata\\local\\temp\\pip-req-build-cyx2iv05\n",
      "  Resolved https://github.com/hitsz-ids/synthetic-data-generator.git to commit 0fc9ea290d5836d079d029c8d6702e526c2676a4\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: click in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (3.0.0)\n",
      "Requirement already satisfied: faker>=10 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (27.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (8.2.0)\n",
      "Requirement already satisfied: joblib>=1.4.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.4.2)\n",
      "Requirement already satisfied: loguru in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (0.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (3.9.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.10.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.40.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.5.3)\n",
      "Requirement already satisfied: pluggy in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.0.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (17.0.0)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.0.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=0.24 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.14.0)\n",
      "Requirement already satisfied: table-evaluator in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (1.6.1)\n",
      "Requirement already satisfied: torch>=2 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sdgx==0.2.4.dev0) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from faker>=10->sdgx==0.2.4.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from openai>=1.10.0->sdgx==0.2.4.dev0) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from pydantic>=2->sdgx==0.2.4.dev0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from pydantic>=2->sdgx==0.2.4.dev0) (2.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from scikit-learn<2,>=0.24->sdgx==0.2.4.dev0) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from torch>=2->sdgx==0.2.4.dev0) (3.15.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from torch>=2->sdgx==0.2.4.dev0) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from torch>=2->sdgx==0.2.4.dev0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from torch>=2->sdgx==0.2.4.dev0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from torch>=2->sdgx==0.2.4.dev0) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from click->sdgx==0.2.4.dev0) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from importlib-metadata->sdgx==0.2.4.dev0) (3.20.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from loguru->sdgx==0.2.4.dev0) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from matplotlib->sdgx==0.2.4.dev0) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from pandas->sdgx==0.2.4.dev0) (2024.1)\n",
      "Collecting pandas (from sdgx==0.2.4.dev0)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ed/30/b97456e7063edac0e5a405128065f0cd2033adfe3716fb2256c186bd41d0/pandas-2.0.3-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "Requirement already satisfied: psutil in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from table-evaluator->sdgx==0.2.4.dev0) (5.9.0)\n",
      "Requirement already satisfied: dython==0.7.3 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from table-evaluator->sdgx==0.2.4.dev0) (0.7.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from table-evaluator->sdgx==0.2.4.dev0) (0.13.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from pandas->sdgx==0.2.4.dev0) (2024.1)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from dython==0.7.3->table-evaluator->sdgx==0.2.4.dev0) (0.3.7)\n",
      "Collecting psutil (from table-evaluator->sdgx==0.2.4.dev0)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/91/87fa6f060e649b1e1a7b19a4f5869709fbf750b7c8c262ee776ec32f3028/psutil-6.1.0-cp37-abi3-win_amd64.whl (254 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.10.0->sdgx==0.2.4.dev0) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.10.0->sdgx==0.2.4.dev0) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.10.0->sdgx==0.2.4.dev0) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.10.0->sdgx==0.2.4.dev0) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.10.0->sdgx==0.2.4.dev0) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from python-dateutil>=2.4->faker>=10->sdgx==0.2.4.dev0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from jinja2->torch>=2->sdgx==0.2.4.dev0) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elvin\\.conda\\envs\\synthetic-data-generator\\lib\\site-packages (from sympy->torch>=2->sdgx==0.2.4.dev0) (1.3.0)\n",
      "Building wheels for collected packages: sdgx\n",
      "  Building wheel for sdgx (pyproject.toml): started\n",
      "  Building wheel for sdgx (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sdgx: filename=sdgx-0.2.4.dev0-py3-none-any.whl size=255204 sha256=f84fa6f76622bba96259daa272314e42aa131a2b48b4105fe24527f90e036b5c\n",
      "  Stored in directory: C:\\Users\\Elvin\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-4uww2jbp\\wheels\\a3\\7c\\29\\b6529b1098dfaed856ca7c2c6dfd0113422a7a8f29d63c6a5c\n",
      "Successfully built sdgx\n",
      "Installing collected packages: psutil, pandas, sdgx\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.0\n",
      "    Uninstalling psutil-5.9.0:\n",
      "      Successfully uninstalled psutil-5.9.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "Successfully installed pandas-2.0.3 psutil-5.9.1 sdgx-0.2.4.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/hitsz-ids/synthetic-data-generator.git 'C:\\Users\\Elvin\\AppData\\Local\\Temp\\pip-req-build-cyx2iv05'\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Elvin\\.conda\\envs\\synthetic-data-generator\\Lib\\site-packages\\~andas'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "copulas 0.8.0 requires pandas<2,>=1.3.4; python_version >= \"3.10\" and python_version < \"3.11\", but you have pandas 2.0.3 which is incompatible.\n",
      "sdmetrics 0.9.0 requires pandas<2,>=1.5.0; python_version >= \"3.10\", but you have pandas 2.0.3 which is incompatible.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkzQVyvRr7bH"
   },
   "source": [
    "We demonstrate with a single table data synthetic example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a1JTesuSr7bH",
    "ExecuteTime": {
     "end_time": "2024-11-29T03:16:48.413123Z",
     "start_time": "2024-11-29T03:16:48.399180Z"
    }
   },
   "source": [
    "from sdgx.data_connectors.csv_connector import CsvConnector\n",
    "from sdgx.data_loader import DataLoader\n",
    "from sdgx.data_models.metadata import Metadata"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNCC1XASr7bH"
   },
   "source": [
    "# 1. Load data\n",
    "\n",
    "The demo data set for this demonstration is a risk control data set used to predict whether an individual will default on a loan. This dataset contains the following features:\n",
    "\n",
    "| Column name | Meaning |\n",
    "|-----------------------|-----------------------|\n",
    "| loan_id | loan ID |\n",
    "| user_id | user ID |\n",
    "| total_loan | Total loan amount |\n",
    "| year_of_loan | Loan period |\n",
    "...\n",
    "\n",
    "This code shows the process of loading real data:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fo4RAlowr7bH",
    "outputId": "7c82f12e-0ded-43ca-fb67-459bc5022052",
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:23.985567Z",
     "start_time": "2024-11-29T03:18:22.967222Z"
    }
   },
   "source": [
    "# In the future, this part of the function will be integrated into `sdgx.processor`\n",
    "import os \n",
    "import requests\n",
    "\n",
    "\n",
    "def download_file(url, path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully to {path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file from {url}\")\n",
    "\n",
    "# download dataset from github\n",
    "# This datajset can be downloaded through sdgx.utils \n",
    "dataset_url = \"https://raw.githubusercontent.com/aialgorithm/Blog/master/projects/‰∏ÄÊñáÊ¢≥ÁêÜÈ£éÊéßÂª∫Ê®°ÂÖ®ÊµÅÁ®ã/train_internet.csv\"\n",
    "file_path = 'train_internet.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    download_file(dataset_url, file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to train_internet.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x5t8M4E6r7bI",
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:26.467442Z",
     "start_time": "2024-11-29T03:18:26.449340Z"
    }
   },
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path_obj = Path(file_path)\n",
    "\n",
    "# Create a data connector and data loader for large csv data\n",
    "# SDG will load data with chunk, can reduce memory usage.\n",
    "data_connector = CsvConnector(path=path_obj)\n",
    "# For small data you can use DataFrameConnector\n",
    "# from sdgx.data_connectors.dataframe_connector import DataFrameConnector\n",
    "# data_connector = DataFrameConnector(dataframe)\n",
    "data_loader = DataLoader(data_connector)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Metadata from Dataloader\n",
    "\n",
    "sdgx supports creating metadata from pd.DataFrame or DataLoader, and also supports creating metadata from scratch from blank metadata (but this method is not recommended because it is more troublesome).\n",
    "\n",
    "In this example, we use `from_dataloader` to create the first Metadata."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:30.373315Z",
     "start_time": "2024-11-29T03:18:27.845644Z"
    }
   },
   "source": [
    "loan_metadata = Metadata.from_dataloader(data_loader)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-11-29 11:18:27.846\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msdgx.data_models.metadata\u001B[0m:\u001B[36mfrom_dataloader\u001B[0m:\u001B[36m318\u001B[0m - \u001B[1mInspecting metadata...\u001B[0m\n",
      "\u001B[32m2024-11-29 11:18:30.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msdgx.data_models.metadata\u001B[0m:\u001B[36mupdate_primary_key\u001B[0m:\u001B[36m527\u001B[0m - \u001B[1mPrimary Key updated: {'user_id', 'loan_id'}.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs first understand some common member variables in Metadata.\n",
    "\n",
    "The most important and commonly used method is to use `column_list` to view column information. This variable returns a list. The order of columns corresponds to the order of the actual table."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:30.389263Z",
     "start_time": "2024-11-29T03:18:30.375305Z"
    }
   },
   "source": [
    "loan_metadata.column_list"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_id',\n",
       " 'user_id',\n",
       " 'total_loan',\n",
       " 'year_of_loan',\n",
       " 'interest',\n",
       " 'monthly_payment',\n",
       " 'class',\n",
       " 'sub_class',\n",
       " 'work_type',\n",
       " 'employer_type',\n",
       " 'industry',\n",
       " 'work_year',\n",
       " 'house_exist',\n",
       " 'house_loan_status',\n",
       " 'censor_status',\n",
       " 'marriage',\n",
       " 'offsprings',\n",
       " 'issue_date',\n",
       " 'use',\n",
       " 'post_code',\n",
       " 'region',\n",
       " 'debt_loan_ratio',\n",
       " 'del_in_18month',\n",
       " 'scoring_low',\n",
       " 'scoring_high',\n",
       " 'pub_dero_bankrup',\n",
       " 'early_return',\n",
       " 'early_return_amount',\n",
       " 'early_return_amount_3mon',\n",
       " 'recircle_b',\n",
       " 'recircle_u',\n",
       " 'initial_list_status',\n",
       " 'earlies_credit_mon',\n",
       " 'title',\n",
       " 'policy_code',\n",
       " 'f0',\n",
       " 'f1',\n",
       " 'f2',\n",
       " 'f3',\n",
       " 'f4',\n",
       " 'f5',\n",
       " 'is_default']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use Inspectors to automatically label column types\n",
    "\n",
    "Currently, when a sdgx's Metadata module pd.DataFrame or DataLoader is created, it will load Inspectors, automatically scan some data (not all data), and label the columns in the table according to the logic of each Inspector.\n",
    "\n",
    "Currently, we support automatic inference of multiple data types, and sdgx supports the following basic types:\n",
    "- bool\n",
    "- int\n",
    "- float\n",
    "- datetime\n",
    "- discrete\n",
    "- id\n",
    "\n",
    "Basic data types guarantee that each column will be labeled to one of the data types.\n",
    "\n",
    "sdgx also supports the following data types, and the sdgx team will continue to add data types:\n",
    "\n",
    "- english_name\n",
    "- email\n",
    "- china_mainland_mobile_phone\n",
    "- china_mainland_id\n",
    "- china_mainland_postcode\n",
    "- unified_social_credit_code\n",
    "- china_mainland_address\n",
    "- chinese_name\n",
    "\n",
    "If you need to query a column of a certain data type, you can access it through `.{column_name}_columns`, for example: access the datetime column through `.datetime_columns`, and access the english_name column through `english_name_columns`.\n",
    "\n",
    "For example, we can access discrete columns through `.discrete_columns`, which will return a set containing the set of column names that are considered **discrete** columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ILAVWcEr7bI",
    "outputId": "5da2b0cf-ccec-4d61-b982-fd410275eb12",
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:30.499210Z",
     "start_time": "2024-11-29T03:18:30.489212Z"
    }
   },
   "source": [
    "# Automatically infer discrete columns\n",
    "loan_metadata.discrete_columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class',\n",
       " 'earlies_credit_mon',\n",
       " 'employer_type',\n",
       " 'industry',\n",
       " 'issue_date',\n",
       " 'sub_class',\n",
       " 'work_type',\n",
       " 'work_year'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can view `int_columns`, `bool_columns` and other columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:30.902756Z",
     "start_time": "2024-11-29T03:18:30.886801Z"
    }
   },
   "source": [
    "# No Bool columns in current tabular data.\n",
    "loan_metadata.bool_columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:31.090571Z",
     "start_time": "2024-11-29T03:18:31.083590Z"
    }
   },
   "source": [
    "# check int columns\n",
    "loan_metadata.int_columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'censor_status',\n",
       " 'del_in_18month',\n",
       " 'early_return',\n",
       " 'early_return_amount',\n",
       " 'early_return_amount_3mon',\n",
       " 'f0',\n",
       " 'f1',\n",
       " 'f2',\n",
       " 'f3',\n",
       " 'f4',\n",
       " 'f5',\n",
       " 'house_exist',\n",
       " 'house_loan_status',\n",
       " 'initial_list_status',\n",
       " 'is_default',\n",
       " 'loan_id',\n",
       " 'marriage',\n",
       " 'offsprings',\n",
       " 'policy_code',\n",
       " 'post_code',\n",
       " 'pub_dero_bankrup',\n",
       " 'recircle_b',\n",
       " 'region',\n",
       " 'scoring_high',\n",
       " 'scoring_low',\n",
       " 'title',\n",
       " 'total_loan',\n",
       " 'use',\n",
       " 'user_id',\n",
       " 'year_of_loan'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `datetime_columns` to view datetime types, but note that datetime type needs to add formats before data processing, **datetime formats need to completely correspond to datetime columns**. \n",
    "\n",
    "For specific operations, please refer to the manual interface of metadata below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:31.460546Z",
     "start_time": "2024-11-29T03:18:31.445595Z"
    }
   },
   "source": [
    "loan_metadata.datetime_columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'earlies_credit_mon', 'issue_date'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è It is worth noting that Inspectors work well in most cases, but all types in tabular data may not be fully covered, or there may be incomplete coverage.\n",
    "\n",
    "Therefore, before proceeding to the next step of training the model or further processing the data, we still recommend that data analysts **check** all the labeling of data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Understand the inspect_level mechanism in Metadata\n",
    " \n",
    "Since Metadata will run multiple Inspectors when it is created, the same data column may be labeled multiple times. For example, a column is marked as PostCode and discrete at the same time. In fact, this column is a post code column. \n",
    "\n",
    "From this, we use `inspect_level` to solve this problem. Different inspectors have different inspect levels, and the final mark of the final column is determined by the mark with the higher inspect level."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:32.018881Z",
     "start_time": "2024-11-29T03:18:32.004929Z"
    }
   },
   "source": [
    "# ¬∑column_inspect_level¬∑ records the inspect_level values of all inspectors\n",
    "# the default inspect_level is 10 \n",
    "loan_metadata.column_inspect_level"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function sdgx.data_models.metadata.Metadata.<lambda>()>,\n",
       "            {'email_columns': 30,\n",
       "             'unified_social_credit_code_columns': 30,\n",
       "             'chinese_company_name_columns': 40,\n",
       "             'id_columns': 20,\n",
       "             'china_mainland_address_columns': 30,\n",
       "             'china_mainland_postcode_columns': 20,\n",
       "             'english_name_columns': 40,\n",
       "             'china_mainland_id_columns': 30,\n",
       "             'datetime_columns': 20,\n",
       "             'int_columns': 10,\n",
       "             'float_columns': 10,\n",
       "             'empty_columns': 90,\n",
       "             'bool_columns': 10,\n",
       "             'china_mainland_mobile_phone_columns': 30,\n",
       "             'chinese_name_columns': 40,\n",
       "             'discrete_columns': 10,\n",
       "             'const_columns': 80})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Metadata manual interface\n",
    "\n",
    "Metadata supports the following manual interfaces, which can finely modify column labels one by one according to your ideas:\n",
    "- query: Query the tag of a certain column.\n",
    "- get: Get all tags by key.\n",
    "- setÔºöSet tags, will convert value to set if value is not a set.\n",
    "- add: Add tags.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:32.391587Z",
     "start_time": "2024-11-29T03:18:32.378587Z"
    }
   },
   "source": [
    "loan_metadata.set('id_columns', {'loan_id'})\n",
    "\n",
    "loan_metadata.id_columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loan_id'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that currently only the datetime type needs to `add formats`, and before data processing, datetime formats need to completely correspond to datetime columns (otherwise the column will be deleted during the data preprocessing process), other data types do not need it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:32.750626Z",
     "start_time": "2024-11-29T03:18:32.739077Z"
    }
   },
   "source": [
    "# datetime_format has no content, which will cause an error in the subsequent process.\n",
    "loan_metadata.datetime_format"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str, {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above four basic methods only apply to columns.\n",
    "\n",
    "For the dict type datetime format, it is recommended to assign values directly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:33.121041Z",
     "start_time": "2024-11-29T03:18:33.109081Z"
    }
   },
   "source": [
    "datetime_format = {\n",
    "    'issue_date': '%Y-%m-%d',\n",
    "    'earlies_credit_mon': '%b-%Y'\n",
    "}\n",
    "loan_metadata.datetime_format = datetime_format\n",
    "# You can also try this.\n",
    "# loan_metadata.datetime_format[\"issue_date\"] = \"%Y-%m-%d\"\n",
    "# loan_metadata.datetime_format[\"earlies_credit_mon\"] = \"%b-%Y\"\n",
    "loan_metadata.datetime_format"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issue_date': '%Y-%m-%d', 'earlies_credit_mon': '%b-%Y'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get the exact data type of each column\n",
    "\n",
    "We provide the get_column_data_type method to query the final data type of each column:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:33.492940Z",
     "start_time": "2024-11-29T03:18:33.480010Z"
    }
   },
   "source": [
    "loan_metadata.get_column_data_type(\"f0\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:33.691293Z",
     "start_time": "2024-11-29T03:18:33.677334Z"
    }
   },
   "source": [
    "loan_metadata.get_column_data_type(\"recircle_u\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to get the exact data type of all columns, you can combine it with the `.column_list` method:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:34.050918Z",
     "start_time": "2024-11-29T03:18:34.038895Z"
    }
   },
   "source": [
    "for each_col in loan_metadata.column_list:\n",
    "    print(f'{each_col}: {loan_metadata.get_column_data_type(each_col)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_id: id\n",
      "user_id: int\n",
      "total_loan: int\n",
      "year_of_loan: int\n",
      "interest: float\n",
      "monthly_payment: float\n",
      "class: discrete\n",
      "sub_class: discrete\n",
      "work_type: discrete\n",
      "employer_type: discrete\n",
      "industry: discrete\n",
      "work_year: discrete\n",
      "house_exist: int\n",
      "house_loan_status: int\n",
      "censor_status: int\n",
      "marriage: int\n",
      "offsprings: int\n",
      "issue_date: datetime\n",
      "use: int\n",
      "post_code: int\n",
      "region: int\n",
      "debt_loan_ratio: float\n",
      "del_in_18month: int\n",
      "scoring_low: int\n",
      "scoring_high: int\n",
      "pub_dero_bankrup: int\n",
      "early_return: int\n",
      "early_return_amount: int\n",
      "early_return_amount_3mon: int\n",
      "recircle_b: int\n",
      "recircle_u: float\n",
      "initial_list_status: int\n",
      "earlies_credit_mon: datetime\n",
      "title: int\n",
      "policy_code: const\n",
      "f0: int\n",
      "f1: int\n",
      "f2: int\n",
      "f3: int\n",
      "f4: int\n",
      "f5: int\n",
      "is_default: int\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7. Setting the categorical encoder for ML Model.\n",
    "This feature now only be available in `CTGANSynthesizerModel`.\n",
    "For some ML Model such as `CTGANSynthesizerModel`, it supports specifying the encoder for categorical columns. You can use `CategoricalEncoderType` to check which encoder you can use."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:34.422165Z",
     "start_time": "2024-11-29T03:18:34.409158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sdgx.data_models.metadata import CategoricalEncoderType\n",
    "CategoricalEncoderType"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Literal['onehot', 'label', 'frequency']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:34.777434Z",
     "start_time": "2024-11-29T03:18:34.768464Z"
    }
   },
   "cell_type": "code",
   "source": "loan_metadata.discrete_columns",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class',\n",
       " 'earlies_credit_mon',\n",
       " 'employer_type',\n",
       " 'industry',\n",
       " 'issue_date',\n",
       " 'sub_class',\n",
       " 'work_type',\n",
       " 'work_year'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Then you can specify the column's encoder directly by setting the `categorical_encoder`.\n",
    "Tips: \n",
    "1. For datetime columns if we used the `DatetimeFormatter` in processors, we don't need to select an encoder for it. Cause the processor has been transform it to a float.\n",
    "2. If we don't specify the encoder for some columns, the model will using its default logic to select encoder. For `CTGANSynthesizerModel`, it will use 'onehot'."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:35.165828Z",
     "start_time": "2024-11-29T03:18:35.151876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loan_metadata.categorical_encoder = {\n",
    "    \"class\": \"label\",\n",
    "    \"sub_class\": \"label\",    \n",
    "    \"employer_type\": \"onehot\", # this line can be removed for CTGANSynthesizerModel, cause the default encoder is \"onehot\" in the model.\n",
    "    \"industry\": \"frequency\",\n",
    "    \"work_year\": \"label\"\n",
    "    # \"work_type\" using default encoder, we are not specified its encoder.\n",
    "    # \"issue_date\" and \"earlies_credit_mon\" are datetime columns. We are not specified its encoder.\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Furthermore, if the columns unique values are too large, using onehot encoder for ML Model can cause performance problem because of the large training dimensions. We can use `categorical_threshold` to automatically select encoder."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T03:18:35.537990Z",
     "start_time": "2024-11-29T03:18:35.524681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loan_metadata.categorical_threshold = {\n",
    "    # if the length of unique values less than 100, use onehot encoder.\n",
    "    100: \"frequency\", # if the length of unique values greater than 100, use frequency encoder.\n",
    "    10000: \"label\" # if the length of unique values greater than 10000, use label encoder.\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In `CTGANSynthesizerModel`, if we both specify the `categorical_threshold` and `categorical_encoder`, the `categorical_encoder` are firstly used even if the column matched a regulation in `categorical_threshold`. "
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "sdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
